name: Train Model

on:
  push:
    branches: [ main ]
    paths:
      - 'src/**'
      - 'scripts/**'
      - 'requirements.txt'
  schedule:
    - cron: '0 0 * * 0'
  workflow_dispatch:

jobs:
  train:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    
    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Download Kaggle data
      env:
        KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
        KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
      run: python scripts/download_data.py || echo "âš ï¸ Data download failed"
    
    - name: STEP 1 - Data Loader Agent
      id: data_loader
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        echo "::group::ðŸ“Š Data Loader Agent Output"
        python scripts/run_pipeline.py --train --no-submission
        echo "::endgroup::"
    
    - name: STEP 2 - Feature Engineer Agent
      id: feature_engineer
      run: |
        echo "::group::ðŸ“ˆ Feature Engineer Agent Output"
        # VÃ©rification du dossier src/models vu dans ton image
        python -c "from pathlib import Path; print('âœ… Success') if Path('src/models').exists() else print('âš ï¸ Path not found')"
        echo "::endgroup::"
    
    - name: STEP 3 - Model Trainer Agent
      id: model_trainer
      run: |
        echo "::group::ðŸ¤– Model Trainer Agent Output"
        # VÃ©rifie si le modÃ¨le existe dans le dossier models
        python -c "import joblib; from pathlib import Path; model_path = Path('src/models/baseline_model.pkl'); print(f'âœ… Found: {model_path}') if model_path.exists() else print('â„¹ï¸ Model not yet created')"
        echo "::endgroup::"
    
    - name: STEP 4 - Submission Agent
      id: submission
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        echo "::group::ðŸ“ Submission Agent Output"
        python scripts/run_pipeline.py --no-train --no-detect-drift
        echo "::endgroup::"

    - name: Data Drift Detection
      id: drift_detection
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        echo "::group::ðŸ” Data Drift Detection"
        python scripts/run_pipeline.py --detect-drift --no-train --no-submission || echo "âš ï¸ Drift failed"
        echo "::endgroup::"
    
    - name: Upload model artifact
      uses: actions/upload-artifact@v4
      with:
        name: trained-model
        path: src/models/baseline_model.pkl
        if-no-files-found: warn
    
    - name: Summary
      if: always()
      run: |
        echo "## ðŸ“Š Pipeline Execution Summary" >> $GITHUB_STEP_SUMMARY
        echo "| Step | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| ðŸ“Š Data Loader | ${{ steps.data_loader.outcome }} |" >> $GITHUB_STEP_SUMMARY
        echo "| ðŸ“ˆ Feature Engineer | ${{ steps.feature_engineer.outcome }} |" >> $GITHUB_STEP_SUMMARY
        echo "| ðŸ¤– Model Trainer | ${{ steps.model_trainer.outcome }} |" >> $GITHUB_STEP_SUMMARY
        echo "| ðŸ“ Submission | ${{ steps.submission.outcome }} |" >> $GITHUB_STEP_SUMMARY
        echo "| ðŸ” Drift Detection | ${{ steps.drift_detection.outcome }} |" >> $GITHUB_STEP_SUMMARY